{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Obstacle_detection",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harsh-not-haarsh/ASSisted-Driving/blob/master/Obstacle_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOo5WQDfbs2x",
        "colab_type": "code",
        "outputId": "1121cae9-e6c3-4ee3-90f6-bf6b3eae98a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "import os\n",
        "import skimage.io\n",
        "import time\n",
        "import re\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt \n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np \n",
        "import random\n",
        "import math\n",
        "import glob\n",
        "# root directory \n",
        "ROOT_DIR= os.path.abspath(\"../../\")\n",
        "sys.path.append(ROOT_DIR)\n",
        "from config import Config\n",
        "import utils\n",
        "import model as modellib\n",
        "import visualize\n",
        "from model import log\n",
        "\n",
        "# importing mscoco configurations\n",
        "#!wget http://images.cocodataset.org/zips/train2017.zip\n",
        "import coco\n",
        "#saving logs and trained models\n",
        "COCO_MODEL_DIR = os.path.join(ROOT_DIR,\"logs\")\n",
        "VIDEO_DIR = os.path.join(ROOT_DIR, \"etc\")\n",
        "VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, 'out.mp4')\n",
        "#COCO Weights\n",
        "COCO_WEIGHTS_FILE=os.path.join(ROOT_DIR,\"mask_rcnn_coco.h5\")\n",
        "if not os.path.exists(COCO_WEIGHTS_FILE):\n",
        "\tutils.download_trained_weights(COCO_WEIGHTS_FILE)\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "#VIDEO_SAVE_DIR=os.path.join(ROOT_DIR,\"media\")\n",
        "#Directory of the images\n",
        "IMAGE_DIR=os.path.join(ROOT_DIR,\"media\")\n",
        "print(5)\n",
        "# We will be running on inference mode here\n",
        "class _config_(coco.CocoConfig):\n",
        "\t# since we are running on config mode here we will run one picture at a time\n",
        "\tGPU_COUNT=1\n",
        "\tIMAGES_PER_GPU=3\n",
        "# Call the above function to implement these assigned features\n",
        "config=_config_()\n",
        "def display_instances(image, boxes, masks, ids, names, scores): \n",
        "    \"\"\" \n",
        "        take the image and results and apply the mask, box, and Label \n",
        "    \"\"\"\n",
        "    n_instances = boxes.shape[0] \n",
        "    colors = visualize.random_colors(n_instances) \n",
        "    \n",
        "    if not n_instances: \n",
        "        print('NO INSTANCES TO DISPLAY') \n",
        "    else: \n",
        "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0] \n",
        "    \n",
        "    for i, color in enumerate(colors): \n",
        "        if not np.any(boxes[i]): \n",
        "            continue\n",
        "    \n",
        "        y1, x1, y2, x2 = boxes[i] \n",
        "        label = names[ids[i]] \n",
        "        score = scores[i] if scores is not None else None\n",
        "        caption = '{} {:.2f}'.format(label, score) if score else label \n",
        "        mask = masks[:, :, i] \n",
        "    \n",
        "        image = visualize.apply_mask(image, mask, color) \n",
        "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2) \n",
        "        image = cv2.putText( \n",
        "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
        "        ) \n",
        "    \n",
        "    return image \n",
        "# inferencing it\n",
        "model=modellib.MaskRCNN(mode=\"inference\",model_dir=COCO_MODEL_DIR,config=config)\n",
        "# Loading weights\n",
        "model.load_weights(COCO_WEIGHTS_FILE,by_name=True)\n",
        "import cv2\n",
        "class_names=['BG', 'god', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']\n",
        "# Taking an image to test upon\n",
        "#temp=file_names = next(os.walk(IMAGE_DIR))[2]\n",
        "#image = skimage.io.imread(os.path.join(IMAGE_DIR, random.choice(file_names)))\n",
        "#results=model.detect([image],verbose=1)\n",
        "#r=results[0]\n",
        "#visualize.display_instances(image,r['rois'],r['masks'],r['class_ids'],class_names,r['scores'])\n",
        "#VIDEO_DIR=os.path.join(\"ROOT_DIR\",\"media\")\n",
        "capture = cv2.VideoCapture(os.path.join(VIDEO_DIR, 'VID_20190510_151319(0).mp4')) \n",
        "frame_count=0\n",
        "frames=[]\n",
        "batch_size=3\n",
        "#vs = cv2.VideoCapture(VIDEO_STREAM) \n",
        "\"\"\"\n",
        "writer = None\n",
        "\n",
        "capture.set(cv2.CAP_PROP_POS_FRAMES, 1000); \n",
        "    \n",
        "i = 0\n",
        "while i < 20000: \n",
        "  # read the next frame from the file \n",
        "  grabbed, frame = capture.read() \n",
        "  i += 1\n",
        "     \n",
        "  # If the frame was not grabbed, then we have reached the end \n",
        "  # of the stream \n",
        "  if not grabbed: \n",
        "    print (\"Not grabbed.\") \n",
        "    break; \n",
        "  else:\n",
        "    print(\"grabbed\")\n",
        "      \n",
        "  # Run detection \n",
        "  results = model.detect([frame], verbose=1) \n",
        "    \n",
        "  # Visualize results \n",
        "  r = results[0] \n",
        "  masked_frame = display_instances(frame, r['rois'], r['masks'], r['class_ids'], \n",
        "                            class_names, r['scores']) \n",
        "      \n",
        "  # Check if the video writer is None \n",
        "  if writer is None: \n",
        "    # Initialize our video writer \n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\") \n",
        "    writer = cv2.VideoWriter(VIDEO_SAVE_DIR, fourcc, 30, \n",
        "      (masked_frame.shape[1], masked_frame.shape[0]), True) \n",
        "     \n",
        "  # Write the output frame to disk \n",
        "  writer.write(masked_frame) \n",
        "      \n",
        "# Release the file pointers \n",
        "print(\"[INFO] cleaning up...\") \n",
        "writer.release() \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "writer=None\n",
        "\n",
        "while True:\n",
        "    ret, frame = capture.read()\n",
        "    # Bail out when the video file ends\n",
        "    if not ret:\n",
        "        break        \n",
        "    # Save each frame of the video to a list\n",
        "    \n",
        "    frame_count += 1\n",
        "    frames.append(frame)\n",
        "    if len(frames) == batch_size:\n",
        "        results = model.detect(frames, verbose=0)\n",
        "        for i, item in enumerate(zip(frames, results)):\n",
        "            frame = item[0]\n",
        "            r = item[1]\n",
        "            frame = display_instances(\n",
        "                frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
        "            )\n",
        "            if writer is None: \n",
        "              \n",
        "              \n",
        "              print(\"helo\")\n",
        "          \n",
        "                \n",
        "    # Initialize our video writer \n",
        "              fourcc = cv2.VideoWriter_fourcc(*\"XVID\") \n",
        "              writer = cv2.VideoWriter(VIDEO_SAVE_DIR, fourcc, 30, \n",
        "      (frame.shape[1], frame.shape[0]), True) \n",
        "     \n",
        "  # Write the output frame to disk \n",
        "        writer.write(frame) \n",
        "        frames=[]    \n",
        "# Release the file pointers \n",
        "print(\"[INFO] cleaning up...\") \n",
        "writer.release() \n",
        "           # name = '{0}.jpg'.format(frame_count + i - batch_size)\n",
        "           # name = os.path.join(VIDEO_SAVE_DIR, name)\n",
        "           # cv2.imwrite(name, frame)\n",
        "        # Clear the frames array to start the next batch\n",
        "        #frames =[]\n",
        "images = list(glob.iglob(os.path.join(VIDEO_SAVE_DIR, '*.jpg')))\n",
        "# Sort the images by name index.\n",
        "images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n",
        "\n",
        "#video = cv2.VideoCapture(os.path.join(VIDEO_DIR, 'VID_20190510_151319(0).mp4'));\n",
        "\n",
        "# # Find OpenCV version\n",
        "#if (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.') if int(major_ver)  < 3 :\n",
        "#  fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
        "#  print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
        "#else :\n",
        "#  fps = video.get(cv2.CAP_PROP_FPS)\n",
        "#  print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
        "\n",
        "#video.release();\n",
        "#def make_video(outvid, images=None, fps=10, size=None,\n",
        " #              is_color=True, format=\"FMP4\"):\n",
        "\"\"\"\n",
        "    Create a video from a list of images.\n",
        " \n",
        "    @param      outvid      output video\n",
        "    @param      images      list of images to use in the video\n",
        "    @param      fps         frame per second\n",
        "    @param      size        size of each frame\n",
        "    @param      is_color    color\n",
        "    @param      format      see http://www.fourcc.org/codecs.php\n",
        "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html    \"\"\"\n",
        "\"\"\" \n",
        "  from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
        "    fourcc = VideoWriter_fourcc(*format)\n",
        "    vid = None\n",
        "    for image in images:\n",
        "        if not os.path.exists(image):\n",
        "            raise FileNotFoundError(image)\n",
        "        img = cv2.imread(image)\n",
        "        if vid is None:\n",
        "            if size is None:\n",
        "                size = img.shape[1], img.shape[0]\n",
        "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
        "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
        "            img = resize(img, size)\n",
        "        vid.write(img)\n",
        "    vid.release()\n",
        "    return vid\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "\n",
        "# Directory of images to run detection on\n",
        "#ROOT_DIR = os.getcwd()\n",
        "\n",
        "#images = list(glob.iglob(os.path.join(VIDEO_SAVE_DIR, '*.*')))\n",
        "# Sort the images by integer index\n",
        "#images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n",
        "\n",
        "#outvid = os.path.join(VIDEO_DIR, \"out.mp4\")\n",
        "#make_video(outvid, images, fps=10)\n",
        "#from google.colab import files\n",
        "#files.download('etc/out.mp4')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "helo\n",
            "[INFO] cleaning up...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a4ccb48800d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;31m#make_video(outvid, images, fps=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'etc/out.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0mstarted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_threading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: etc/out.mp4"
          ]
        }
      ]
    }
  ]
}